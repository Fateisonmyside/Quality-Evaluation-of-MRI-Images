{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "clOqRV8YFaHn",
        "outputId": "91824442-1ad1-413f-e427-3c2aa510f1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://dyslexia.computing.clemson.edu/BET_BSE/BET_BSE_DATA.zip\n",
            "5084545024/5084537526 [==============================] - 54s 0us/step\n",
            "5084553216/5084537526 [==============================] - 54s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/BET_BSE_DATA.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "url = \"https://dyslexia.computing.clemson.edu/BET_BSE/BET_BSE_DATA.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"BET_BSE_DATA.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvGntklbICi6"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"MosMedData\")\n",
        "with zipfile.ZipFile(\"BET_BSE_DATA.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1RupSBLI4aL"
      },
      "outputs": [],
      "source": [
        "paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/BET_BSE_DATA/files\", x)\n",
        "    for x in os.listdir(\"MosMedData/BET_BSE_DATA/files\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QToAAcBIJX_F"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "\n",
        "\n",
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    return volume.astype(\"float32\")\n",
        "\n",
        "def resize_volume(img):\n",
        "    \"\"\"Resize across z-axis\"\"\"\n",
        "    # Set the desired depth\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_scan(path):\n",
        "    \"\"\"Read and resize volume\"\"\"\n",
        "    # Read scan\n",
        "    volume = read_nifti_file(path)\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "    # Resize width, height and depth\n",
        "    # Read scan\n",
        "    volume = resize_volume(volume)\n",
        "    return volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "wQPPgg3s5xHi",
        "outputId": "a5690ff4-1fb5-4618-9bf3-96095dd846e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86ef392d-28b1-4d0a-b53e-a7ca3e01b020\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86ef392d-28b1-4d0a-b53e-a7ca3e01b020\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Label_file.csv to Label_file.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "uploaded = files.upload()\n",
        "\n",
        "ex = pd.read_csv('Label_file.csv')\n",
        "\n",
        "ex[\"Recognizable-Facial-Feature\"]=ex[\"Recognizable-Facial-Feature\"].eq('Yes').mul(1)\n",
        "ex[\"Brain-Feature-Loss\"]=ex[\"Brain-Feature-Loss\"].eq('Yes').mul(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7_AQXdeHK3T"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "y_train1=[]\n",
        "y_train2=[]\n",
        "scan=[]\n",
        "for path in paths :\n",
        "  if count <500 :\n",
        "    scan.append(process_scan(path))\n",
        "    y_train1.append(ex.iloc[count,1])\n",
        "    y_train2.append(ex.iloc[count,2])\n",
        "  count+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmi9JUB__sS3"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "y_train1_val=[]\n",
        "y_train2_val=[]\n",
        "val=[]\n",
        "for path in paths :\n",
        "  if count >500 and count <800 :\n",
        "    val.append(process_scan(path))\n",
        "    y_train1_val.append(ex.iloc[count,1])\n",
        "    y_train2_val.append(ex.iloc[count,2])\n",
        "  count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6CQqKfsFpBq"
      },
      "outputs": [],
      "source": [
        "train_loader = tf.data.Dataset.from_tensor_slices((scan, y_train2))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((val, y_train2_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y89SqsY6OW-",
        "outputId": "8fdbe447-4353-4859-eec4-e659962a491b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"3dcnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 64, 1)  0         \n",
            "                             ]                                   \n",
            "                                                                 \n",
            " conv3d (Conv3D)             (None, 126, 126, 62, 64)  1792      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 63, 63, 31, 64)   0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 63, 63, 31, 64)   256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 61, 61, 29, 64)    110656    \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 30, 30, 14, 64)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 30, 30, 14, 64)   256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 28, 28, 12, 64)    110656    \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 14, 14, 6, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 6, 64)    256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 12, 12, 4, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPooling  (None, 6, 6, 2, 128)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 6, 6, 2, 128)     512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling3d (G  (None, 128)              0         \n",
            " lobalAveragePooling3D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 478,977\n",
            "Trainable params: 478,337\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def train_model(width=128, height=128, depth=64):\n",
        "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(units=256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model.\n",
        "model = train_model(width=128, height=128, depth=64)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1utT5oeF-mG"
      },
      "outputs": [],
      "source": [
        "train_dataset = (\n",
        "    train_loader.shuffle(len(scan))\n",
        "    .batch(3)\n",
        "    .prefetch(2)\n",
        ")\n",
        "\n",
        "validation_dataset = (\n",
        "    validation_loader.shuffle(len(val))\n",
        "    .batch(3)\n",
        "    .prefetch(2)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPYv1h17uOuV",
        "outputId": "a7409bee-89f9-40c1-a01c-122d0da59dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "167/167 - 6055s - loss: 0.6901 - acc: 0.5720 - val_loss: 0.7407 - val_acc: 0.5418 - 6055s/epoch - 36s/step\n",
            "Epoch 2/3\n",
            "167/167 - 6042s - loss: 0.6621 - acc: 0.6340 - val_loss: 1.0621 - val_acc: 0.5418 - 6042s/epoch - 36s/step\n",
            "Epoch 3/3\n",
            "167/167 - 6031s - loss: 0.6642 - acc: 0.6260 - val_loss: 0.8503 - val_acc: 0.5418 - 6031s/epoch - 36s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86c26dcb90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "learning_rate = 0.0001\n",
        "learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    learning_rate, decay_steps=100, decay_rate=0.96, staircase=True\n",
        ")\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate_schedule),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "\n",
        "# Define callbacks.\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"3d_image_classification.h5\", save_best_only=True\n",
        ")\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch\n",
        "epochs = 3\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=10,\n",
        "    shuffle=True,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnQ8_0SGGP5H",
        "outputId": "28a70e20-64fe-4219-aa9e-810a12df7d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "73/73 - 253s - loss: 0.6918 - acc: 0.5479 - val_loss: 0.7310 - val_acc: 0.4035 - 253s/epoch - 3s/step\n",
            "Epoch 2/10\n",
            "73/73 - 248s - loss: 0.6836 - acc: 0.5571 - val_loss: 0.7364 - val_acc: 0.4211 - 248s/epoch - 3s/step\n",
            "Epoch 3/10\n",
            "73/73 - 248s - loss: 0.6908 - acc: 0.5251 - val_loss: 0.7398 - val_acc: 0.3333 - 248s/epoch - 3s/step\n",
            "Epoch 4/10\n",
            "73/73 - 248s - loss: 0.6873 - acc: 0.5388 - val_loss: 0.7350 - val_acc: 0.4386 - 248s/epoch - 3s/step\n",
            "Epoch 5/10\n",
            "73/73 - 245s - loss: 0.6891 - acc: 0.5799 - val_loss: 0.7270 - val_acc: 0.3860 - 245s/epoch - 3s/step\n",
            "Epoch 6/10\n",
            "73/73 - 243s - loss: 0.6818 - acc: 0.5388 - val_loss: 0.7396 - val_acc: 0.4035 - 243s/epoch - 3s/step\n",
            "Epoch 7/10\n",
            "73/73 - 244s - loss: 0.6983 - acc: 0.5023 - val_loss: 0.7356 - val_acc: 0.4035 - 244s/epoch - 3s/step\n",
            "Epoch 8/10\n",
            "73/73 - 242s - loss: 0.6929 - acc: 0.5023 - val_loss: 0.7239 - val_acc: 0.3684 - 242s/epoch - 3s/step\n",
            "Epoch 9/10\n",
            "73/73 - 245s - loss: 0.6895 - acc: 0.5251 - val_loss: 0.7428 - val_acc: 0.3860 - 245s/epoch - 3s/step\n",
            "Epoch 10/10\n",
            "73/73 - 247s - loss: 0.6885 - acc: 0.5297 - val_loss: 0.7400 - val_acc: 0.4211 - 247s/epoch - 3s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff26189d610>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOLv9yqCIxN4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbGLMwIojsrf"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "y_test2=[]\n",
        "scan_test=[]\n",
        "for path in paths :\n",
        "  if count > 800 :\n",
        "    scan_test.append(process_scan(path))\n",
        "    y_test2.append(ex.iloc[count,2])\n",
        "  count+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = tf.data.Dataset.from_tensor_slices((scan_test, y_test2))\n",
        "test_dataset = (\n",
        "    test_loader.shuffle(len(scan_test))\n",
        "    .batch(3)\n",
        "    .prefetch(2)\n",
        ")\n"
      ],
      "metadata": {
        "id": "0KzaJNrPGr-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xD18A4D2k5tZ"
      },
      "outputs": [],
      "source": [
        "TP=0\n",
        "TN=0\n",
        "FP=0\n",
        "FN=0\n",
        "for p in range(len(scan)) :\n",
        "  prediction = model.predict(np.expand_dims(scan[p], axis=0))[0]\n",
        "  if prediction[0] >= .5 and int(y_train1[p]) ==1 :\n",
        "    TP+=1\n",
        "  elif prediction[0] >= .5 and int(y_train1[p]) ==0 :\n",
        "    FP+=1\n",
        "  elif prediction[0] < .5 and int(y_train1[p]) ==0 :\n",
        "    TN+=1\n",
        "  elif prediction[0] < .5 and int(y_train1[p]) ==1 :\n",
        "    FN+=1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TP=0\n",
        "TN=0\n",
        "FP=0\n",
        "FN=0\n",
        "for p in range(len(scan)) :\n",
        "  prediction = model.predict(np.expand_dims(scan[p], axis=0))[0]\n",
        "  if prediction[0] <= .5 and int(y_train2[p]) ==1 :\n",
        "    TP+=1\n",
        "  elif prediction[0] > .5 and int(y_train2[p]) ==0 :\n",
        "    TN+=1\n",
        "  elif prediction[0] <= .5 and int(y_train2[p]) ==0 :\n",
        "    FP+=1\n",
        "  elif prediction[0] > .5 and int(y_train2[p]) ==1 :\n",
        "    FN+=1"
      ],
      "metadata": {
        "id": "MsVC6bvF-wzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mUBg6tRfkwD",
        "outputId": "7afcf5d5-6bf6-411e-abd3-cd114aaec6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model is 79.87 percent confident that CT scan is normal\n",
            "This model is 20.13 percent confident that CT scan is abnormal\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(np.expand_dims(scan[398], axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "class_names = [\"normal\", \"abnormal\"]\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(\n",
        "        \"This model is %.2f percent confident that CT scan is %s\"\n",
        "        % ((100 * score), name)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TP : \",  TP , \"TN : \", TN, \"FP : \", FP , \"FN : \",FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p555tLgPUrX",
        "outputId": "6d92ed1b-d955-47e8-c96b-ad9d80d6931c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP :  178 TN :  0 FP :  322 FN :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCOu6CxTg9kW",
        "outputId": "4b06415c-d04a-440f-b9a1-b08347e130fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.356 precision :  0.356 recall :  1.0 F1 :  0.5250737463126843\n"
          ]
        }
      ],
      "source": [
        "accuracy = (TP + TN)/(TN + TP + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "F1 = (2*TP)/(2*TP + FP + FN)\n",
        "\n",
        "print(\"accuracy :\" , accuracy ,\"precision : \", precision ,  \"recall : \", recall , \"F1 : \", F1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIX80qJTrcKj"
      },
      "outputs": [],
      "source": [
        "TP=0\n",
        "TN=0\n",
        "FP=0\n",
        "FN=0\n",
        "for p in range(len(scan)) :\n",
        "  prediction = model.predict(np.expand_dims(scan[p], axis=0))[0]\n",
        "  if prediction[0] >= .5 and int(y_train1[p]) ==1 :\n",
        "    TP+=1\n",
        "  elif prediction[0] >= .5 and int(y_train1[p]) ==0 :\n",
        "    FP+=1\n",
        "  elif prediction[0] < .5 and int(y_train1[p]) ==0 :\n",
        "    TN+=1\n",
        "  elif prediction[0] < .5 and int(y_train1[p]) ==1 :\n",
        "    FN+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOetr5LKr0Vk",
        "outputId": "4661bc99-5cd0-48f8-f62f-67e04bafbd5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.356 precision :  0.356 recall :  1.0 F1 :  0.5250737463126843\n"
          ]
        }
      ],
      "source": [
        "accuracy = (TP + TN)/(TN + TP + FP + FN)\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n",
        "F1 = (2*TP)/(2*TP + FP + FN)\n",
        "\n",
        "print(\"accuracy :\" , accuracy  ,\"precision : \", precision ,  \"recall : \", recall , \"F1 : \", F1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(train_dataset)\n",
        "dict(zip(model.metrics_names, result))"
      ],
      "metadata": {
        "id": "z5XQDgl3PN8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5580c70-0da1-48be-bcf0-773984b228ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167/167 [==============================] - 671s 4s/step - loss: 0.7076 - acc: 0.6440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.6439999938011169, 'loss': 0.7076351046562195}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(test_dataset)\n",
        "dict(zip(model.metrics_names, result))"
      ],
      "metadata": {
        "id": "YO_DKmYuUYUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
        "    ax[i].plot(model.history.history[metric])\n",
        "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
        "    ax[i].set_title(\"Model {}\".format(metric))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(metric)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ],
      "metadata": {
        "id": "eG_LNNqdS0Qm",
        "outputId": "99f1f612-cce8-4f65-d277-d98d19d2b84a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-4248b7f18338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
